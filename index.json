[{"authors":null,"categories":null,"content":"TRAILに関する最新情報をお届けします．\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://matsuolab.github.io/roomba_hack/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/authors/admin/","section":"authors","summary":"TRAILに関する最新情報をお届けします．","tags":null,"title":"TRAIL Admin","type":"authors"},{"authors":["jumpei-arima"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"451d184f9c1e53301faf72f3ade4d5c6","permalink":"https://matsuolab.github.io/roomba_hack/authors/jumpei-arima/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/authors/jumpei-arima/","section":"authors","summary":"","tags":null,"title":"有馬 純平","type":"authors"},{"authors":["tatsuya-matsushima"],"categories":null,"content":"人間と共生できるような適応的なロボットの開発と，そのようなロボットを作ることにより生命性や知能を構成的に理解することに興味があります． 特に現在は，深層生成モデルを用いた環境のダイナミクスのモデリング（世界モデル）・モデルベース強化学習・メタ模倣学習に関して研究を行っています．\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"96eea6d6aacba886dc9c6ad4c3b6f83f","permalink":"https://matsuolab.github.io/roomba_hack/authors/tatsuya-matsushima/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/authors/tatsuya-matsushima/","section":"authors","summary":"人間と共生できるような適応的なロボットの開発と，そのようなロ","tags":null,"title":"松嶋 達也","type":"authors"},{"authors":["yuya-ikeda"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4c9f99a2ef4096b81e6d0a08880581e8","permalink":"https://matsuolab.github.io/roomba_hack/authors/yuya-ikeda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/authors/yuya-ikeda/","section":"authors","summary":"","tags":null,"title":"池田 悠也","type":"authors"},{"authors":null,"categories":null,"content":" 開発環境 ロボットシステムの開発環境に使われている要素の概要を理解する   ROSとは ロボット開発によく用いられるROSの概要を理解する   ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"f1fb9b3e706d6a8e7af6ee8a67c187b1","permalink":"https://matsuolab.github.io/roomba_hack/course/chap1/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap1/","section":"course","summary":"ロボットシステムの基礎知識","tags":null,"title":"Chapter 1","type":"book"},{"authors":null,"categories":null,"content":" ロボットシステムにおけるセンシング・アクチュエーション・通信① センサの値を読み取りロボットを動かしてみよう   ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"b03bbdc309591542a3a0cf48966f3d87","permalink":"https://matsuolab.github.io/roomba_hack/course/chap2/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap2/","section":"course","summary":"センシング・アクチュエーション・通信①","tags":null,"title":"Chapter 2","type":"book"},{"authors":null,"categories":null,"content":" ロボットシステムにおけるセンシング・アクチュエーション・通信② 複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう   ロボットシステムにおけるセンシング・アクチュエーション・通信③ 複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう   ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"b891a66c1b2d8231b078e52b380c46a1","permalink":"https://matsuolab.github.io/roomba_hack/course/chap3/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap3/","section":"course","summary":"センシング・アクチュエーション・通信②","tags":null,"title":"Chapter 3","type":"book"},{"authors":null,"categories":null,"content":" Localization   Navigation ロボットシステムの開発環境に使われている要素の概要を理解する   ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"ef4ff386bad3919cafa8bb6a9000e1a5","permalink":"https://matsuolab.github.io/roomba_hack/course/chap4/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap4/","section":"course","summary":"自律移動","tags":null,"title":"Chapter 4","type":"book"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"c5b6edce25a3188d94c102a439d09587","permalink":"https://matsuolab.github.io/roomba_hack/course/chap5/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap5/","section":"course","summary":"3次元画像認識","tags":null,"title":"Chapter 5","type":"book"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"8f714aaf4a960d30c5c5c987c0a4c5d1","permalink":"https://matsuolab.github.io/roomba_hack/course/chap6/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap6/","section":"course","summary":"複雑なロボットシステムの実装・分散処理","tags":null,"title":"Chapter 6","type":"book"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"2f5bc53e4f4c671993cb760f7d80fa51","permalink":"https://matsuolab.github.io/roomba_hack/course/chap7/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap7/","section":"course","summary":"最終プロジェクト準備","tags":null,"title":"Chapter 7","type":"book"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"2adf7951016803e68618153c45700bf0","permalink":"https://matsuolab.github.io/roomba_hack/course/chap8/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/roomba_hack/course/chap8/","section":"course","summary":"最終プロジェクト","tags":null,"title":"Chapter 8","type":"book"},{"authors":null,"categories":null,"content":"  -- Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview 実ロボット(roomba)を利用した演習を通じて、ロボットシステムの仕組みから、センシング・認識・行動について研究開発に必要な最低限の知識や実装スキルを習得する。\nCourses in this program  Chapter 1 ロボットシステムの基礎知識\n  Chapter 2 センシング・アクチュエーション・通信①\n  Chapter 3 センシング・アクチュエーション・通信②\n  Chapter 4 自律移動\n  Chapter 5 3次元画像認識\n  Chapter 6 複雑なロボットシステムの実装・分散処理\n  Chapter 7 最終プロジェクト準備\n  Chapter 8 最終プロジェクト\n  Meet your instructor TRAIL Admin FAQs Are there prerequisites? There are no prerequisites for the first course.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"97ede4bb026d52eb5ee887238b8270ea","permalink":"https://matsuolab.github.io/roomba_hack/course/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/roomba_hack/course/","section":"course","summary":"rooombaを用いた実ロボットシステム入門","tags":null,"title":"📊 ロボットシステム入門","type":"book"},{"authors":null,"categories":null,"content":"複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう\nLearn 前回の演習では，速度と時間の指令を使ってロボットを制御しました．\n周囲に障害物が何もない状況や，ロボットの滑りがない環境では，速度と時間のコマンドを使って思った通りにロボットを動かすことができるかもしれませんが，実環境では，ロボットの周囲には障害物が存在しますし，移動距離で制御する方が直感的です．\n前回の演習のようにロボットに速度と時間を一回与えて，その通りに動かすようなフィードフォワード制御ではなく，今回は，ロボットが逐次的にセンサの情報を反映して振る舞いを変えるフィードバック制御を行なってみましょう．\nオドメトリのセンサ情報を使ってロボットを動かしてみよう まずは，ロボットのタイヤの回転量から計算される移動距離であるオドメトリ（odometry）を使った制御をしてみましょう．\nオドメトリのメッセージ（/odom）の中身を見てみよう roombaのオドメトリの情報は，/odomトピックにpublishされています．\nrostopic echo /odomをしてみるとメッセージとしてどんな情報が流れているかわかります． rostopic echo -n 1 /odom root@dynamics:~/roomba_hack# rostopic echo -n 1 /odom header: seq: 2115 stamp: secs: 1649692132 nsecs: 791056254 frame_id: \u0026quot;odom\u0026quot; child_frame_id: \u0026quot;base_footprint\u0026quot; pose: pose: position: x: -0.014664691872894764 y: -0.0010878229513764381 z: 0.0 orientation: x: 0.0 y: 0.0 z: 0.0056752621080531414 w: 0.9999838955703261 covariance: [0.08313143998384476, 0.00019857974257320166, 0.0, 0.0, 0.0, 0.004368376452475786, 0.00019857988809235394, 0.015032557770609856, 0.0, 0.0, 0.0, -0.26573312282562256, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0043683769181370735, -0.26573312282562256, 0.0, 0.0, 0.0, 6.021446704864502] twist: twist: linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] ---  \nrostopic type /odomをしてみると，メッセージとして，nav_msgs/Odometry型が使われていることがわかります． rostopic type /odom root@dynamics:~/roomba_hack# rostopic type /odom nav_msgs/Odometry  \nnav_msgs/Odometry型のドキュメントを確認してみると，このメッセージはposeとtwistで構成されていることがわかります．\nposeは．（child_frameから見た）ロボットの推定姿勢（位置と回転角）を表していて，covarianceにはその不確かさを表す共分散が記録されています．\n一方，twistは，（child_frameから見た）ロボットの速度を表していて，poseと同様にcovarianceにはその不確かさを表す共分散が記録されています．\nなお，メッセージ型の定義は，rosmsg info nav_msgs/Odometryすることでもコマンドから確認できます． rosmsg info nav_msgs/Odometry root@dynamics:~/roomba_hack# rosmsg info nav_msgs/Odometry std_msgs/Header header uint32 seq time stamp string frame_id string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/Pose pose geometry_msgs/Point position float64 x float64 y float64 z geometry_msgs/Quaternion orientation float64 x float64 y float64 z float64 w float64[36] covariance geometry_msgs/TwistWithCovariance twist geometry_msgs/Twist twist geometry_msgs/Vector3 linear float64 x float64 y float64 z geometry_msgs/Vector3 angular float64 x float64 y float64 z float64[36] covariance  \nクォータニオン(quaternion) さて，/odomのトピックでは，ロボットの回転角はクォータニオン（quaternion）で記述されています．\nクォータニオンは，日本語では四元数と呼ばれ，3次元空間上での回転角を表現する方法の一つで，4つの要素を持つベクトルで表現されます．\nクォータニオンによる3次元回転の表現は，角度を連続的にかつ簡潔に表現できるためROSではよく用いられます（その他には，オイラー角による表現や回転行列による表現があります）．\nそれぞれの回転角に関する表現のメリット・デメリットを調べてみましょう（「ジンバルロック」などのキーワードで調べるとよりよく理解できると思います）．\nクォータニオンからオイラー角へは，tfパッケージのtf.transformations.euler_from_quaternionを使うことで変換できます（ドキュメント）．\nサブスクライバ（subscriber)の仕組みを知ろう それでは，オドメトリ/odomの情報を使った制御の実装の例としてnavigation_tutorialパッケージの中のsimple_control2.pyを見てみましょう（github）．\n前回までに強調されてきた通り，ROSは非同期分散のシステムを簡単に作ることができるのが特徴です． そのため，ロボットから非同期に送られてくる/odomの情報をうまく扱うことが重要です．\n実装例にあるように，Pythonによるノードの実装では，クラスとして定義するのがわかりやすい方法でしょう．\n実装例では，SimpleControlllerクラスとして，simple_controllerというノードを定義しています． 以下のように，ノードを初期化する際に，コマンドを/cmd_velトピックに送信するパブリッシャ（publisher)と，/odomを受信するサブスクライバ(subscriber)を作成しています．\nclass SimpleController: def __init__(self): rospy.init_node('simple_controller', anonymous=True) # Publisher self.cmd_vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=10) # Subscriber odom_sub = rospy.Subscriber('/odom', Odometry, self.callback_odom) self.x = None self.y = None self.yaw = None while self.x is None: rospy.sleep(0.1)  パブリッシャの使い方は前回のsimple_control.pyの実装を確認してください．\nパブリッシャと同様に，サブスクライバはrospyのSubscriberを用いて作成できます． サブスクライバの特徴として，メッセージを受信した時の処理であるコールバック（callback）を定義できます．\nこの実装例では，self.callback_odomとして定義されており，インスタンスの属性（self.x, self.y, self.yaw）を，受信したメッセージで変更するようなプログラムになっています．\ndef callback_odom(self, data): self.x = data.pose.pose.position.x self.y = data.pose.pose.position.y self.yaw = self.get_yaw_from_quaternion(data.pose.pose.orientation)  つまり，self.xには/odomから受信した位置のx座標，self.yには位置のy座標，self.yawには，回転角のyawを格納しています．\nクォータニオンとして受信した姿勢の回転角のyaw成分を取り出すためのself.get_yaw_from_quaternionは以下のようになっています（オイラー角はroll, pitch, yawの順で返ってくるのでe[2]でyawを取得しています）．\ndef get_yaw_from_quaternion(self, quaternion): e = tf.transformations.euler_from_quaternion( (quaternion.x, quaternion.y, quaternion.z, quaternion.w)) return e[2]  これらのセンサの値を使うことで，以下のように，指定した距離ロボットが移動するまで直進させ続けたり，指定した角度までロボットが回転するまで回転させ続けることができるようになります．\n直進\ndef go_straight(self, dis, velocity=0.3): vel = Twist() x0 = self.x y0 = self.y while(np.sqrt((self.x-x0)**2+(self.y-y0)**2)\u0026lt;dis): vel.linear.x = velocity vel.angular.z = 0.0 self.cmd_vel_pub.publish(vel) rospy.sleep(0.1) self.stop()  右回転\ndef turn_right(self, yaw, yawrate=-0.5): vel = Twist() yaw0 = self.yaw while(abs(self.yaw-yaw0)\u0026lt;np.deg2rad(yaw)): vel.linear.x = 0.0 vel.angular.z = yawrate self.cmd_vel_pub.publish(vel) rospy.sleep(0.1) self.stop()  左回転\ndef turn_left(self, yaw, yawrate=0.5): vel = Twist() yaw0 = self.yaw while(abs(self.yaw-yaw0)\u0026lt;np.deg2rad(yaw)): vel.linear.x = 0.0 vel.angular.z = yawrate self.cmd_vel_pub.publish(vel) rospy.sleep(0.1) self.stop()  それでは，オドメトリを使って実際にロボットを制御してみましょう．\n演習 【jetson・開発マシン】ブランチをmaster切り替えて最新の状態にする cd roomba_hack git fetch git checkout master git pull origin master ./BUILD-DOCKER-IMAGE.sh   【jetson・開発マシン】それぞれdockerコンテナを起動 注：前回との間に仕様が変わりました（簡単になりました）． 以下のコマンドの\u0026lt;\u0026lt;IP ADDRESS\u0026gt;\u0026gt;の部分を自分のroomba（jetson）のIPアドレスに変更して起動してください（例：192.168.10.70）．\ncd roomba_hack ./RUN-DOCKER-CONTAINER.sh \u0026lt;\u0026lt;IP ADDRESS\u0026gt;\u0026gt;   【jetson・開発マシン】ビルドをしてパスを通す try it! パスを通した後にcatkin_wsの中にあるパッケージが一覧rospack listに追加されているかを確認してみよう\n(docker) cd catkin_ws (docker) catkin_make (docker) source ./devel/setup.bash   【jetson】ROSマスタ、各種ノードを起動 (docker) roslaunch roomba_bringup bringup.launch   ROSメッセージの可視化 【開発PC】topicの確認 /odomの型を確認\n(docker) rostopic type /odom  /odomの中身を確認\n(docker) rostopic echo /odom   オドメトリを使ったフィードバック制御 simple_control2.pyを実行してみよう．\n開発PCでteleopのコードを実行しましょう\n(docker) roslaunch roomba_teleop teleop.launch  このプログラムを動かすときには，コントローラのYボタンを押してからBボタンを押してautoモードにしておきましょう．\n1メートルほど前に進んだあと，左に90度程度旋回し，右に90度程度旋回したら成功です．\n(docker) rosrun navigation_tutorial simple_control2.py  try it! simple_control2.pyの中身を読んでコードを変更してみよう\n","date":1649116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649116800,"objectID":"2ee7ed9f0716848dbd6ffe877377e500","permalink":"https://matsuolab.github.io/roomba_hack/course/chap3/sensing2/","publishdate":"2022-04-05T00:00:00Z","relpermalink":"/roomba_hack/course/chap3/sensing2/","section":"course","summary":"複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう\n","tags":null,"title":"ロボットシステムにおけるセンシング・アクチュエーション・通信②","type":"book"},{"authors":null,"categories":null,"content":"Learn TF 自己位置推定 演習 Dockerfileにmaclを追加してBuildする \n amclをlaunchして、自己位置推定する \n amclのparamをチューニングする \n","date":1642809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642809600,"objectID":"29d802971ebbc674f8dd6b80aeddda91","permalink":"https://matsuolab.github.io/roomba_hack/course/chap4/localization/","publishdate":"2022-01-22T00:00:00Z","relpermalink":"/roomba_hack/course/chap4/localization/","section":"course","summary":"","tags":null,"title":"Localization","type":"book"},{"authors":null,"categories":null,"content":"ロボットシステムの開発環境に使われている要素の概要を理解する\nスライド https://docs.google.com/presentation/d/1-q6zq3vV91GTj7mw9uqwT4B8LyHDpFHBNVi4lEyCa5A/edit?usp=sharing\nLearn Linuxコマンド    command 　説明 option     ls ディレクトリ内のファイル・ディレクトリの表示 -l: 詳細を表示 -a: 全て表示   mkdir ディレクトリ作成    cd ディレクトリ移動    mv ファイル移動    rm ファイル削除 -r:ディレクトリ内を再起的に削除 -f:強制削除   cat           ssh ssh \u0026lt;username\u0026gt;@\u0026lt;hostname\u0026gt; -p \u0026lt;port\u0026gt; -i \u0026lt;identity_file\u0026gt;  エディタ  vim  チュートリアル： vimtuter   emacs  git/GitHub  gitとは  add push pull fetch clone merge reset    GitHubとは   docker   Dockerとは\n  DockerFileのビルド\ndocker build -t \u0026lt;image_name\u0026gt;:\u0026lt;tag_name\u0026gt; -f \u0026lt;Dockerfile\u0026gt; \u0026lt;relative_dir\u0026gt;    Docker Image\n# Docker image一覧 docker images # Docker Imageのダウンロード docker pull \u0026lt;image_name\u0026gt;:\u0026lt;tag_name\u0026gt; # 削除 docker rmi \u0026lt;image_id\u0026gt; # 不要なDocker imageを消す docker image prune    Docker Container\n# Docker containerの起動 docker run \u0026lt;image_name\u0026gt; \u0026lt;command\u0026gt; # Docker container一覧 docker ps -a # Docker containerに接続 docker exec -it \u0026lt;container_name\u0026gt; bash  ※docker runでよく使うオプション\n -it  標準入出力有効になる   --name \u0026lt;container_name\u0026gt;  コンテナの名前の指定   --rm  コンテナを抜けた際に自動的にコンテナを削除する   --gpus all  コンテナに全gpuを渡す gpuの個数を指定する場合は all の代わりに数字(0, 1,\u0026hellip;) gpuを指定する場合は --gpus '\u0026quot;device=0,1\u0026quot;'   -v \u0026lt;host/path/to/dir:container/path/to/dir\u0026gt;  コンテナ内にホストのディレクトリをマウントする   -p \u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt;  ホストのポートをコンテナのポートにマップする コンテナ内でwebサーバを動かす場合などに使う   --net=host  コンテナとホストでネットワークを共有する(IPアドレスなどが同じになる) ROSノードをコンテナ内で動かす場合などはこれを使うと楽   --privileged  コンテナからのデバイスへのアクセスを許可 コンテナからWEBカメラにアクセスしたいときなど      演習 【ssh】開発用PCにsshする vim ~/.ssh/config ssh robot_dev2   【Linuxコマンド】個人のディレクトリを作成し移動する robot_dev2@robot-dev2:~$ mkdir yikeda robot_dev2@robot-dev2:~$ cd yikeda   【git】roomba_hackリポジトリをcloneし移動する robot_dev2@robot-dev2:~/yikeda$ git clone https://github.com/matsuolab/roomba_hack.git robot_dev2@robot-dev2:~/yikeda$ cd roomba_hack   【git】devブランチにcheckoutする robot_dev2@robot-dev2:~/yikeda/roomba_hack$ git checkout dev   【docker】roomba_hackの開発環境のdocker imageをビルドする robot_dev2@robot-dev2:~/yikeda/roomba_hack$ ./BUILD-DOCKER-IMAGE.sh   【ssh】jetsonにsshする robot_dev2@robot-dev2:~/yikeda/roomba_hack$ ssh roomba_dev1   【ssh】VNCを使う robot_dev2@robot-dev2:~/yikeda/roomba_hack$ exit ssh robot_dev2 -L 5900:localhost:5900  手元のVNC viewerでlocalhost:5900を開く\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"2a1ada4f20c1997bdd8592ad8bf5f9b1","permalink":"https://matsuolab.github.io/roomba_hack/course/chap1/%E9%96%8B%E7%99%BA%E7%92%B0%E5%A2%83/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/roomba_hack/course/chap1/%E9%96%8B%E7%99%BA%E7%92%B0%E5%A2%83/","section":"course","summary":"ロボットシステムの開発環境に使われている要素の概要を理解する\n","tags":null,"title":"開発環境","type":"book"},{"authors":null,"categories":null,"content":"センサの値を読み取りロボットを動かしてみよう\nLearn ロボットセンサの基礎知識 ロボットが動作するために必要なセンサは大きく2種類に分けられる。\n1つ目が外界センサで、これはロボットが行動する環境の情報を取得するためのセンサーである。 具体的なセンサとして、\n LiDAR デプスカメラ ホイールエンコーダ IMU  などがあげられる。\nセンサのノイズの影響を軽減するため、複数のセンサを組み合わせて利用されることもある。\n2つ目は内界センサで、これは(ロボットアームのような変形可能な)ロボットが自身の内部状態を把握し、位置や姿勢を制御するために使われるセンサーである。\n 関節位置・角度センサ 関節姿勢センサ  などが内界センサである。\n参考\n https://www.jsme.or.jp/jsme-medwiki/14:1013897#:~:text=robot%20sensor  ROSのパッケージ ROSのプログラムはパッケージとして管理される。\nnavigation_tutorailパッケージのファイル構成を示す。\nnavigation_tutorial ├── CMakeLists.txt ├── launch │ ├── amcl.launch │ ├── avoidance.launch │ ├── gmapping.launch │ ├── go_straight.launch │ ├── localization.launch │ ├── map_server.launch │ ├── move_base.launch │ └── navigation.launch ├── package.xml ├── params │ ├── base_global_planner_params.yaml │ ├── base_local_planner_params.yaml │ ├── costmap_common_params.yaml │ ├── dwa_local_planner_params.yaml │ ├── global_costmap_params.yaml │ ├── local_costmap_params.yaml │ └── move_base_params.yaml ├── scripts │ ├── avoidance.py │ ├── simple_control2.py │ └── simple_control.py └── src ├── avoidance.cpp └── go_straight.cpp  作成したプログラムはrosrunコマンドで実行することができる。\n(Python) rosrun navigation_tutorail simple_control2.py (C++) rosrun navigation_tutorail go_straight  launchファイルについてでも同様にroslaunchコマンドで実行することができる。\n(Python) roslaunch navigation_tutorial move_base.launch  実行時にパッケージを指定するので、(パスが通ってさえれば)ディレクトリに関係なく実行が可能である。\nROSのワークスペース ROSのパッケージはワークスペースと呼ばれる作業スペースに配置される。\n一般的にcatkin_wsという名前が使われることが多い。\ncatkin_wsのファイル構成を示す。\ncatkin_ws ├── build ├── devel └── src ├── CMakeLists.txt ├── navigation_tutorial │ ├── CMakeLists.txt │ ├── launch │ ├── package.xml │ ├── params │ ├── scripts │ └── src └── roomba ├── roomba_bringup │ ├── CMakeLists.txt │ ├── config │ ├── launch │ └── package.xml ├── roomba_description │ ├── CMakeLists.txt │ ├── config │ ├── launch │ ├── meshes │ ├── package.xml │ └── urdf ├── roomba_gazebo │ ├── CMakeLists.txt │ ├── launch │ └── package.xml └── roomba_teleop ├── CMakeLists.txt ├── include ├── launch ├── package.xml └── src  catkin_wsのsrc内でパッケージ作成を行い、catkin_ws直下でcatkin_makeコマンドでビルドをすると、buildディレクトリとdevelディレクトリが作成される。\ndevelディレクトリの中のsetup.bashをソースsource devel/setup.bashすることで、ワークスペース内のパッケージのパスを通すことができる。　ROSのコマンド ROSのコマンドのうち、よく用いるものを紹介する。\n Topic関連  rostopic list topicの一覧を表示する rostopic echo 指定されたtopicの中身を表示する rostopic hz topicの配信周波数を取得する rostopic info topicの情報を表示する rostopic pub topicを配信する rostopic type topicの型を確認する   Node関連  rosnode list nodeの一覧を表示する rosnode ping nodeの接続テストを行う rosnode info nodeの情報を表示する rosnode kill nodeをシャットダウンする   Package関連  rospack list packageの一覧を表示する roscd 指定したpackage内に移動する  演習 【jetson・開発マシン】ブランチ切り替え cd roomba_hack git fetch git checkout lec_0405   【jetson・開発マシン】それぞれdockerコンテナを起動 try it! roomba_modeの前後でecho $ROS_MASTER_URIをしてみよう\n参考(ROS_MASTER_URIについて)\n https://qiita.com/srs/items/7d4aeb5e44138f97c770  cd roomba_hack ./RUN-DOCKER-CONTAINER.sh (docker) roomba_mode   【jetson・開発マシン】ビルドをしてパスを通す try it! パスを通した後にcatkin_wsの中にあるパッケージが一覧rospack listに追加されているかを確認してみよう\n(docker) cd catkin_ws (docker) catkin_make (docker) source ./devel/setup.bash   【jetson】ROSマスタ、各種ノードを起動 try it! bringup.launchの中身を読んでみよう\nhint roscd \u0026lt;パッケージ名\u0026gt;とするとパッケージへ簡単に移動ができる\n(docker) roslaunch roomba_bringup bringup.launch   【jetson】RealSenseを起動 cd realsense_docker ./launch_realsense.sh   ROSメッセージの可視化 【開発PC】topicの確認 topic一覧を表示\n(docker) rostopic list  特定のtopicの型を確認\n(docker) rostopic type /camera/color/image_raw (docker) rostopic type /scan  sensor_msgs/LaserScan型 http://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/LaserScan.html sensor_msgs/Image型 http://docs.ros.org/en/noetic/api/sensor_msgs/html/msg/Image.html\n特定のtopicの中身を確認\n(docker) rostopic echo /camera/color/image_raw (docker) rostopic echo /scan  rvizを用いて可視化\n(docker) rviz   【開発PC】topicのpublish(配信) topic/cmd_velの情報を確認\n(docker) rostopic info /cmd_vel  topic/cmd_velの型を確認\n(docker) rostopic type /cmd_vel  geometry_msgs/Twist型 http://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/Twist.html\ntopic/cmd_velをpublish\n(docker) rostopic pub /cmd_vel geometry_msgs/Twist \u0026quot;linear: x: 1.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0\u0026quot;  topicをスクリプトからpublish\n(docker) rosrun navigation_tutorial simple_control.py  try it! simple_control.pyの中身を読んでコードを変更してみよう\n","date":1649116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649116800,"objectID":"ff51cff84b07cbb120bc73f6c20e4a6b","permalink":"https://matsuolab.github.io/roomba_hack/course/chap2/sensing1/","publishdate":"2022-04-05T00:00:00Z","relpermalink":"/roomba_hack/course/chap2/sensing1/","section":"course","summary":"センサの値を読み取りロボットを動かしてみよう\n","tags":null,"title":"ロボットシステムにおけるセンシング・アクチュエーション・通信①","type":"book"},{"authors":null,"categories":null,"content":"複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう\nLearn LiDARのスキャンデータを使って，障害物を回避してみよう 次に，LiDARでスキャンしたデータを使って，障害物を回避するようなプログラムを作ってみましょう．\nLiDARスキャンのメッセージ（/scan）の中身を見てみよう LiDARは，Light Detection And Rangingの略で，レーザ光を使って離れた場所にある物体形状や距離を測定するためのセンサです． 近年では，自動車の自動運転にも用いられることの多いセンサの一つです．\nroombaに搭載されたLiDARセンサ（rplidar）の値は，/scanのトピックに流れていて，rostopic echo /scanをしてみるとメッセージとしてどんな情報が流れているかわかります．\n大きなデータなので今回はテキストに掲載するのは省略しますが，rostopic type /scanをしてみると，メッセージとして，sensor_msgs/LaserScan型が使われていることがわかります． rostopic type /scan root@dynamics:~/roomba_hack# rostopic type /scan sensor_msgs/LaserScan  \nsensor_msgs/LaserScan型の定義を確認してみましょう． メッセージ型の定義は，ドキュメントのほか，rosmsg info sensor_msgs/LaserScanすることでもコマンドから確認できます． rosmsg info sensor_msgs/LaserScan root@dynamics:~/roomba_hack# rosmsg info sensor_msgs/LaserScan std_msgs/Header header uint32 seq time stamp string frame_id float32 angle_min float32 angle_max float32 angle_increment float32 time_increment float32 scan_time float32 range_min float32 range_max float32[] ranges float32[] intensities  \nangle_minにはスキャンの開始角度，angle_maxにはスキャンの終了角度がラジアンで記録されています． angle_incrementは，計測した間隔がラジアンで記録されています． range_maxにはスキャンの間で検出された最大の距離，range_minには最小の距離がメートルで記録されています．\nrvizでLiDARスキャンの値を可視化してみよう rvizでLiDARのスキャン結果を可視化してみましょう．\nLaserScanをAddして，topicに/scanを設定すると，以下のように，ロボットを中心にLiDARによって計測された障害物が赤く表示されます．\n  LiDARスキャンをrvizで可視化  LiDARを使って障害物を回避しよう それでは，LiDARスキャン/scenの情報を使った制御の実装の例としてnavigation_tutorialパッケージの中のavoidance.pyを見てみましょう（github）．\nこのプログラムでは，LiDARを使って進行方向に存在する障害物を見つけ，それを回避しながら進むようにロボットを制御しています．具体的には，\n ロボットの進行方向に物体がなかったら直進 ロボットの右側に障害物があったら左回転 ロボットの左側に障害物があったら右回転  することで障害物を回避（ぶつかる前に方向転換）しています．\nでは，プログラムの中身を見ていきます．\n/odomを使った制御の場合と同様に，ノードを定義する際に，コマンドを送るパブリッシャと，LiDARスキャンのデータを読み取るサブスクライバを作成します．\nclass Avoidance: def __init__(self): rospy.init_node('avoidance', anonymous=True) # Publisher self.cmd_vel_pub = rospy.Publisher('/planner/cmd_vel', Twist, queue_size=10) # Subscriber scan_sub = rospy.Subscriber('/scan', LaserScan, self.callback_scan) self.min_range = None  /scanのコールバックは，\ndef callback_scan(self, data): fov = np.deg2rad(60) min_range = data.range_max min_idx = -1 angle = data.angle_min for idx, r in enumerate(data.ranges): angle += data.angle_increment if -fov\u0026lt;angle\u0026lt;fov: if r\u0026lt;min_range: min_range = r min_idx = idx if min_idx \u0026lt; len(data.ranges)/2.0: self.direction = \u0026quot;RIGHT\u0026quot; else: self.direction = \u0026quot;LEFT\u0026quot; self.min_range = min_range  となっており，正面から左右60度の範囲内で最も短い距離をself.min_rangeに格納し，それが右側にあるのか左側にあるのかをself.directionに格納しています．．\nこのプログラムを実行するとprocessメソッドが（0.1秒おきに）常に実行されます．\ndef process(self): r = rospy.Rate(10) while not rospy.is_shutdown(): vel = Twist() if self.min_range is not None: if self.min_range \u0026gt;= 0.4: vel.linear.x = 0.2 vel.angular.z = 0.0 else: vel.linear.x = 0.0 if self.direction == \u0026quot;RIGHT\u0026quot;: vel.angular.z = 0.5 elif self.direction == \u0026quot;LEFT\u0026quot;: vel.angular.z = -0.5 self.cmd_vel_pub.publish(vel) rospy.sleep(0.1)  processメソッド内部では，格納されたself.min_rangeが0.4（メートル）より大きい場合は，ロボットの前に何もないと判断して直進，小さい場合は，self.directionの値を見て，RIGHTであれば右に障害物があると判断して左回転，LEFTであれば左に障害物があると判断して右回転するようなプログラムになっています．\nそれでは，実際にLiDARを使って障害物を回避するプログラムを実行してみましょう．\n演習 ROSメッセージの可視化 【開発PC】topicの確認 /scanの型を確認\n(docker) rostopic type /scan  /scanの中身を確認\n(docker) rostopic echo /scan   LiDARスキャンを使ったフィードバック制御 avoidance.pyを実行してみよう．\nこのプログラムを動かすときには，コントローラのYボタンを押してからBボタンを押してautoモードにしておきましょう．\n今回はせっかくなので，launchfileから起動してみましょう．s このlaunchfileは，navigation_tutorialパッケージの中のlaunchフォルダの中にあるavoidance.launchに記述されています（github）．\n(docker) roslaunch navigation_tutorial avoidance  ロボットの進行方向に障害物があるときに，それを避けるように方向転換したら成功です．\ntry it! avoidance.pyの中身を読んでコードを変更してみよう\n","date":1649116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649116800,"objectID":"4115bb19a4232d2372987cbff0c843fc","permalink":"https://matsuolab.github.io/roomba_hack/course/chap3/sensing3/","publishdate":"2022-04-05T00:00:00Z","relpermalink":"/roomba_hack/course/chap3/sensing3/","section":"course","summary":"複数のセンサを組み合わせてよりかしこくロボットを動かしてみよう\n","tags":null,"title":"ロボットシステムにおけるセンシング・アクチュエーション・通信③","type":"book"},{"authors":null,"categories":null,"content":"ロボット開発によく用いられるROSの概要を理解する\nLearn ROSの概要 ROS(Robot Operating System)は、ロボット・アプリケーション作成を支援するライブラリとツールを提供するミドルウェアです。 具体的には以下にあげるものをROSは提供しています。\n  メッセージ通信\nプロセス間、コンピュータ間の通信ライブラリが提供されています。用途に応じて、多対多や一対多、非同期、同期などの通信形態を選択することができます。\n  デバイスドライバ\nロボットに搭載される多くのセンサやアクチュエータがROSのAPIで標準化された形で提供されています。\nhttps://github.com/ros-drivers http://wiki.ros.org/Sensors\n  ライブラリ\nロボットを動作させるソフトウェア(ナビゲーション、マニピュレーション)の基本機能の大半が提供されています。\n  視覚化ツール\nロボットの内部状態やセンサ出力を2次元、3次元で視覚化するRvizや3次元動力学シミュレータのGazeboなどが提供されています。\n  パッケージ管理\n多種多様なプログラミング言語(python, C++, \u0026hellip;)、依存関係で記述されたプログラム(パッケージ)同士を統合的にセットアップ、ビルド、テスト、リリースすることが可能です。\nたとえば、経路計画など処理が重いプロセスはC++で、画像認識など機械学習系のプロセスはpythonで実装し、それらプロセス間の通信を容易に実装できる。\n  ROSのメッセージ通信 ロボットシステムでは、多数のプログラムを並列に実行し、それぞれがデータをやりとりします。 それらのプログラム間の通信ライブラリをROSは提供します。\n  ノード(node)\nROSでは、一つのプログラム単位を「ノード(node)」と呼びます。 ノードは、ROSクライアントライブラリを用いて、他のノードとデータをやりとりします。 ROSクライアントライブラリは異なるプログラミング言語で記述されたノードがやりとりできるようにしています。 ノードは、次に述べるトピックの配信・購読、またはサービスの提供・使用が可能です。\n  トピック(topic)\nROSでの、標準的なデータ通信の経路を「トピック(topic)」と呼びます。 ノードはメッセージをトピックへ向けて配信(Publish)し、同様に購読する(Subscribe)ことでトピックからメッセージを受け取ることができます。\nトピックには名前が付けられ、同じトピックに複数のノードがデータを送り、複数のノードがデータを受け取ることができます。\n  メッセージ(message)\nトピックへ配信したり、購読したりするときのROSのデータ型のことを「メッセージ(message)」と呼びます。 メッセージの型はmsgファイルに記述されており、使用言語に依存しないデータ形式になっています。\n以下に、物体やロボットの位置を表す時によく用いるgeomemtry_msgs/PoseStamped型のmsgファイルを示します。 位置情報の時間や座標フレームの情報が含まれるheaderと座標位置を表すposeで定義されています。\nstd_msgs/Header header uint32 seq time stamp string frame_id geometry_msgs/Pose pose geometry_msgs/Point position float64 x float64 y float64 z geometry_msgs/Quaternion orientation float64 x float64 y float64 z float64 w    サービス(service)\n「サービス(service)」はノードが他のノードとお互いに通信するための一つの手段です。 サービスを提供しているノードに引数を渡して、関数の実行結果を戻り値として受け取ることができます。\n呼び出される側のノードは、サービス名とデータ形式の宣言を「アドバタイズ(advertise)」し、呼び出す側のノードは、サービスを「コール(call)」します。\nサービスにおいて送受信されるデータの型はsrvファイルに記述されています。 メッセージと同様使用言語に依存しないデータ形式ですが、メッセージと異なるのは、引数と戻り値の二つの形式を定義する必要があるところです。\n以下に、srvの例としてstd_srvs/SetBoolを示します。 このように引数と戻り値の間に---を入れて定義します。\nbool data --- bool success string message    ROSマスタ(ROS master)\n「ROSマスタ(ROS master)」は、ノード、トピックおよびサービスの名前登録を行い、それぞれのノードが他のノードから見えるようにする役割を担っています。 通信するノード名とトピック名およびサービス名の対応が決定した後、ノード同士が「peer-to-peer」で通信します。\nROSマスタとノード間の通信はXML-RPCを用いて行われます。 ROSマスタを起動するには「roscore」というコマンドを実行します。\n  パラメータサーバ(parameter server)\n「パラメータサーバ(parameter server)」は、設定データを複数のノードで共有するための軽量なサーバです。 各ノードのパラメータを、パラメータサーバで一括して管理できます。 パラメータサーバもROSマスタ同様に「roscore」コマンドで起動します。\nパラメータサーバで扱える型は、整数・小数・真偽値・辞書・リストになります。\n  ROSのデータ通信のまとめ\n    ROS通信  ROSと連動するソフトウェア ROSは以下のソフトウェアと連動して使うためのパッケージが提供されています。\n  OpenCV\nコンピュータビジョンの標準的なライブラリ。\nOpenCVのデータ形式である、MatクラスとROSのメッセージ形式を変換するcv_bridgeや３次元座標上の物体を２次元画像上に投影する機能であるimage_geometryといったパッケージ(vision_opencv)が提供されています。\n  PCL(Point Cloud Library)\n3次元点群処理のライブラリ。\nOpenCV同様PCLのデータ形式とROSのメッセージ形式を変換するパッケージが提供されています。\n  OpenSLAM, Navigation Stack\n移動ロボットの自己位置推定と地図生成を同時に行うSLAM(Simultaneous Localization and Mapping)のソースコードを公開するためのプラットフォームと、。\nROSではOpenSLAMで実装されているgmappingパッケージのラッパーやそれと連携して自律走行を実現するnavigationメタパッケージが提供されています。\n  Move it\n  視覚化ツール  rqt    rqt window   rviz     gazebo  演習 roomba driverを起動し、動作していることを確認する   roombaにアクセスする\nssh roommba    docker containerを起動する\ncd ~/workspace/roomba_hack ./RUN-DOCKER-CONTAINER.sh    roomba driverなどを起動するlaunchファイルを起動する\nroslaunch roomma_bringup roomba_bringup.launch    正常に起動できているかを確認\nrosnode list rostopic list rostopic echo /odom rqt_graph     コントローラーを使って、ロボットを動かす   コントローラーを起動\nroslauunch roomba_teleop roomaba_teleop.launch    コントローラのモード\n 移動・停止 自動・マニュアル ドッキング・アンドッキング    コントローラによる操縦\n  移動ロック解除\nL2を押している時のみ移動コマンドが動作します。\n  左ジョイスティック 縦方向で前進速度(手前に倒すとバック)、横方向は回転速度に対応しています。\n  左矢印 それぞれ、一定に低速度で前進・後退・回転します。\n    正常に起動できているかを確認\nrosnode list rostopic list rostopic echo /cmd_vel rqt_graph rviz    ","date":1642809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642809600,"objectID":"20855653654f6e28e5120898d90797bd","permalink":"https://matsuolab.github.io/roomba_hack/course/chap1/ros/","publishdate":"2022-01-22T00:00:00Z","relpermalink":"/roomba_hack/course/chap1/ros/","section":"course","summary":"ロボット開発によく用いられるROSの概要を理解する\n","tags":null,"title":"ROSとは","type":"book"},{"authors":null,"categories":null,"content":"ロボットシステムの開発環境に使われている要素の概要を理解する\nLearn Navigationシステム Cost Map Global Path Planning Local Path Planning 演習 Dockerfileにnavigationを追加してBuildする \n navigationをlaunchして、rviz上で指定した位置までナビゲーションさせてみる \n navigationをlaunchして、map座標系の位置を指定してナビゲーションさせてみる \n navigationのparamをチューニングする \n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ea25624150d5f3e46f1ef192419e7583","permalink":"https://matsuolab.github.io/roomba_hack/course/chap4/navigation/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/roomba_hack/course/chap4/navigation/","section":"course","summary":"ロボットシステムの開発環境に使われている要素の概要を理解する\n","tags":null,"title":"Navigation","type":"book"},{"authors":null,"categories":null,"content":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"2a0ec8a990dbd78a00c4e15a09364b00","permalink":"https://matsuolab.github.io/roomba_hack/post/20-12-02-icml-best-paper/","publishdate":"2020-12-02T00:00:00Z","relpermalink":"/roomba_hack/post/20-12-02-icml-best-paper/","section":"post","summary":"Congratulations to Jian Yang and Monica Hall for winning the Best Paper Award at the 2020 Conference on Wowchemy for their paper “Learning Wowchemy”.\n","tags":null,"title":"Jian Yang and Monica Hall Win the Best Paper Award at Wowchemy 2020","type":"post"},{"authors":null,"categories":null,"content":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Integer tempus augue non tempor egestas. Proin nisl nunc, dignissim in accumsan dapibus, auctor ullamcorper neque. Quisque at elit felis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget elementum odio. Cras interdum eget risus sit amet aliquet. In volutpat, nisl ut fringilla dignissim, arcu nisl suscipit ante, at accumsan sapien nisl eu eros.\nSed eu dui nec ligula bibendum dapibus. Nullam imperdiet auctor tortor, vel cursus mauris malesuada non. Quisque ultrices euismod dapibus. Aenean sed gravida risus. Sed nisi tortor, vulputate nec quam non, placerat porta nisl. Nunc varius lobortis urna, condimentum facilisis ipsum molestie eu. Ut molestie eleifend ligula sed dignissim. Duis ut tellus turpis. Praesent tincidunt, nunc sed congue malesuada, mauris enim maximus massa, eget interdum turpis urna et ante. Morbi sem nisl, cursus quis mollis et, interdum luctus augue. Aliquam laoreet, leo et accumsan tincidunt, libero neque aliquet lectus, a ultricies lorem mi a orci.\nMauris dapibus sem vel magna convallis laoreet. Donec in venenatis urna, vitae sodales odio. Praesent tortor diam, varius non luctus nec, bibendum vel est. Quisque id sem enim. Maecenas at est leo. Vestibulum tristique pellentesque ex, blandit placerat nunc eleifend sit amet. Fusce eget lectus bibendum, accumsan mi quis, luctus sem. Etiam vitae nulla scelerisque, eleifend odio in, euismod quam. Etiam porta ullamcorper massa, vitae gravida turpis euismod quis. Mauris sodales sem ac ultrices viverra. In placerat ultrices sapien. Suspendisse eu arcu hendrerit, luctus tortor cursus, maximus dolor. Proin et velit et quam gravida dapibus. Donec blandit justo ut consequat tristique.\n","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"be2bd15f022f0d83fe9ffd743881e70c","permalink":"https://matsuolab.github.io/roomba_hack/post/20-12-01-wowchemy-prize/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/roomba_hack/post/20-12-01-wowchemy-prize/","section":"post","summary":"Congratulations to Richard Hendricks for winning first place in the Wowchemy Prize.\n","tags":null,"title":"Richard Hendricks Wins First Place in the Wowchemy Prize","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://matsuolab.github.io/roomba_hack/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://matsuolab.github.io/roomba_hack/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/roomba_hack/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]